{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN4glF8QyHuD07D6KK+3+or"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UfdOAhxxAYRx","executionInfo":{"status":"ok","timestamp":1674450360198,"user_tz":-120,"elapsed":7948,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}},"outputId":"8d527351-28f4-41ad-f46b-6d1cc6f1c0e4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n","58889256/58889256 [==============================] - 0s 0us/step\n"]}],"source":["# importing vgg16\n","import tensorflow\n","from tensorflow.keras.applications import VGG16\n","\n","conv_base = VGG16(weights = 'imagenet', include_top= False,input_shape=(150,150,3))"]},{"cell_type":"code","source":["conv_base.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0qJG49c5BLRH","executionInfo":{"status":"ok","timestamp":1674450407251,"user_tz":-120,"elapsed":65,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}},"outputId":"86789614-02f8-4a17-8aa5-af1b889ab517"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"vgg16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_1 (InputLayer)        [(None, 150, 150, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 150, 150, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 150, 150, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 75, 75, 64)        0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 75, 75, 128)       73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 75, 75, 128)       147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 37, 37, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 37, 37, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 37, 37, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 18, 18, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 18, 18, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 18, 18, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 9, 9, 512)         0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 9, 9, 512)         2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 4, 4, 512)         0         \n","                                                                 \n","=================================================================\n","Total params: 14,714,688\n","Trainable params: 14,714,688\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["## importing data"],"metadata":{"id":"q9steMtkBiAU"}},{"cell_type":"code","source":["!pip install kaggle --upgrade"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q9j79muDBSkU","executionInfo":{"status":"ok","timestamp":1674450485134,"user_tz":-120,"elapsed":3581,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}},"outputId":"d392a928-ef89-498b-c1ea-d269bd59cc33"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: kaggle in /usr/local/lib/python3.8/dist-packages (1.5.12)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.25.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from kaggle) (4.64.1)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.15.0)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.8/dist-packages (from kaggle) (7.0.0)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.8/dist-packages (from kaggle) (2.8.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.8/dist-packages (from kaggle) (2022.12.7)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.8/dist-packages (from kaggle) (1.24.3)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.8/dist-packages (from python-slugify->kaggle) (1.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->kaggle) (2.10)\n"]}]},{"cell_type":"code","source":["# upload the json file\n","'''Mount google drive'''\n","from google.colab import files\n","files.upload()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":91},"id":"G0yiVcu_Bq1-","executionInfo":{"status":"ok","timestamp":1674450525095,"user_tz":-120,"elapsed":8010,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}},"outputId":"4b51ef73-387f-4ab8-bc60-3021f97db9cd"},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-b8bf7fde-b5bf-405e-9e7e-d8978e7a87c8\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b8bf7fde-b5bf-405e-9e7e-d8978e7a87c8\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving kaggle.json to kaggle.json\n"]},{"output_type":"execute_result","data":{"text/plain":["{'kaggle.json': b'{\"username\":\"demianrafeek\",\"key\":\"f6bbfdb213cfa9e126b9bd16006fe254\"}'}"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["# 1- create a directory called \"kaggle\" in root to copy json file to it\n","!mkdir ~/.kaggle"],"metadata":{"id":"6vzHTxoGBzmD","executionInfo":{"status":"ok","timestamp":1674450552185,"user_tz":-120,"elapsed":5,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# 2- copy the file to the directory >> this a heddin file .kaggle\n","!cp kaggle.json ~/.kaggle/"],"metadata":{"id":"Cee-2zIHB8DG","executionInfo":{"status":"ok","timestamp":1674450568606,"user_tz":-120,"elapsed":432,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# 3- check files in the root by run the follow commands\n","%pwd\n","%ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"au19JdpDCADH","executionInfo":{"status":"ok","timestamp":1674450583556,"user_tz":-120,"elapsed":20,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}},"outputId":"52f40945-519e-476e-811d-102c6032bd77"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["kaggle.json  \u001b[0m\u001b[01;34msample_data\u001b[0m/\n"]}]},{"cell_type":"code","source":["# 4- make the directory be able to read/write\n","!chmod 600 ~/.kaggle/kaggle.json"],"metadata":{"id":"ZhRQQN2mCDz3","executionInfo":{"status":"ok","timestamp":1674450600731,"user_tz":-120,"elapsed":12,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# 5- make the dir\n","!mkdir dataset"],"metadata":{"id":"6LEsElhWCH4f","executionInfo":{"status":"ok","timestamp":1674450621317,"user_tz":-120,"elapsed":13,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# go inside\n","%cd /content/dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"toXk2LbkCM4y","executionInfo":{"status":"ok","timestamp":1674450674992,"user_tz":-120,"elapsed":333,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}},"outputId":"d9d30bc7-1850-4e2d-ddb8-617a1092546f"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/dataset\n"]}]},{"cell_type":"code","source":["# from the link >> https://www.kaggle.com/ronitf/heart-disease-uci\n","# go and from the 3 dots choose copy api command and paste here \n","'''don't forget to add ! before the command'''\n","\n","!kaggle datasets download -d shaunthesheep/microsoft-catsvsdogs-dataset\n","# !kaggle datasets download -d ronitf/heart-disease-uci"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ozleAd7ACSM3","executionInfo":{"status":"ok","timestamp":1674450705102,"user_tz":-120,"elapsed":7716,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}},"outputId":"4c0c8b82-4ca6-41d1-ac25-ed997c652e28"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading microsoft-catsvsdogs-dataset.zip to /content/dataset\n"," 98% 773M/788M [00:07<00:00, 109MB/s]\n","100% 788M/788M [00:07<00:00, 112MB/s]\n"]}]},{"cell_type":"code","source":["! unzip /content/dataset/microsoft-catsvsdogs-dataset.zip"],"metadata":{"id":"6gW_G2zSCfdu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## split data into train,validate and test data"],"metadata":{"id":"oRhzCS9jDboi"}},{"cell_type":"code","source":["# now we will separat some images to train dense layers befor we concate it with VGG16 model\n","\n","import os\n","import numpy as np\n","import os, shutil\n","\n","original_dataset_dir = 'train'\n","\n","# The directory where we will\n","# store our smaller dataset\n","base_dir = 'cats_and_dogs_small'\n","try:\n","  os.mkdir(base_dir)\n","except:\n","  print('an exception occured')\n","  pass\n","\n","# Directories for our training,\n","# validation and test splits\n","train_dir = os.path.join(base_dir, 'train')\n","try:\n","  os.mkdir(train_dir)\n","except:\n","  pass  \n","  \n","validation_dir = os.path.join(base_dir, 'validation')\n","try:\n","  os.mkdir(validation_dir)\n","except:\n","  pass   \n","test_dir = os.path.join(base_dir, 'test')\n","try:\n","  os.mkdir(test_dir)\n","except:\n","  pass   \n","\n","# Directory with our training cat pictures\n","train_cats_dir = os.path.join(train_dir, 'cats')\n","try:\n","  os.mkdir(train_cats_dir)\n","except:\n","  pass   \n","\n","# Directory with our training dog pictures\n","train_dogs_dir = os.path.join(train_dir, 'dogs')\n","try:\n","  os.mkdir(train_dogs_dir)\n","except:\n","  pass   \n","\n","# Directory with our validation cat pictures\n","validation_cats_dir = os.path.join(validation_dir, 'cats')\n","try:\n","  os.mkdir(validation_cats_dir)\n","except:\n","  pass \n","\n","# Directory with our validation dog pictures\n","validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n","try:\n","  os.mkdir(validation_dogs_dir)\n","except:\n","  pass   \n","\n","# Directory with our validation cat pictures\n","test_cats_dir = os.path.join(test_dir, 'cats')\n","try:\n","  os.mkdir(test_cats_dir)\n","except:\n","  pass   \n","\n","# Directory with our validation dog pictures\n","test_dogs_dir = os.path.join(test_dir, 'dogs')\n","try:\n","  os.mkdir(test_dogs_dir)\n","except:\n","  pass   \n"],"metadata":{"id":"5jHgDIKYDw6D","executionInfo":{"status":"ok","timestamp":1674451058050,"user_tz":-120,"elapsed":443,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["\n","################   Cats  ###########\n","original_dataset_dir = \"/content/dataset/PetImages/Cat\"\n","# Copy first 1000 cat images to train_cats_dir\n","train_cats_dir = '/content/dataset/cats_and_dogs_small/train/cats'\n","fnames = ['{}.jpg'.format(i) for i in range(1000)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(train_cats_dir, fname)\n","    shutil.copyfile(src, dst)\n","\n","# Copy next 500 cat images to validation_cats_dir\n","validation_cats_dir = '/content/dataset/cats_and_dogs_small/validation/cats'\n","fnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(validation_cats_dir, fname)\n","    shutil.copyfile(src, dst)\n","    \n","# Copy next 500 cat images to test_cats_dir\n","test_cats_dir = '/content/dataset/cats_and_dogs_small/test/cats'\n","fnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(test_cats_dir, fname)\n","    shutil.copyfile(src, dst)\n","    \n","\n","\n","#################   Dogs ##########\n","original_dataset_dir = \"/content/dataset/PetImages/Dog\"\n","# Copy first 1000 dog images to train_dogs_dir\n","train_dogs_dir = '/content/dataset/cats_and_dogs_small/train/dogs'\n","fnames = ['{}.jpg'.format(i) for i in range(1000)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(train_dogs_dir, fname)\n","    shutil.copyfile(src, dst)\n","    \n","# Copy next 500 dog images to validation_dogs_dir\n","validation_dogs_dir = '/content/dataset/cats_and_dogs_small/validation/dogs'\n","fnames = ['{}.jpg'.format(i) for i in range(1000, 1500)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(validation_dogs_dir, fname)\n","    shutil.copyfile(src, dst)\n","    \n","# Copy next 500 dog images to test_dogs_dir\n","test_dogs_dir = '/content/dataset/cats_and_dogs_small/test/dogs'\n","fnames = ['{}.jpg'.format(i) for i in range(1500, 2000)]\n","for fname in fnames:\n","    src = os.path.join(original_dataset_dir, fname)\n","    dst = os.path.join(test_dogs_dir, fname)\n","    shutil.copyfile(src, dst)\n"],"metadata":{"id":"8El9pHosDwmJ","executionInfo":{"status":"ok","timestamp":1674451080906,"user_tz":-120,"elapsed":956,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Data Generator"],"metadata":{"id":"OEnVaeojC3Zy"}},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.imagenet_utils import preprocess_input\n","\n","train_datagen = ImageDataGenerator(\n","    rescale=1./255,\n","    rotation_range=40,\n","    width_shift_range=.2,\n","    height_shift_range=.2,\n","    shear_range=.2,\n","    zoom_range=.2,\n","    horizontal_flip=True,\n","    fill_mode='nearest'\n",")\n","\n","validation_datagen = ImageDataGenerator(rescale=1./255)\n","\n","train_dir = '/content/dataset/cats_and_dogs_small/train'\n","train_generator = train_datagen.flow_from_directory(train_dir,target_size=(150,150),batch_size=20,class_mode='binary')\n","\n","\n","validation_dir = '/content/dataset/cats_and_dogs_small/validation'\n","validation_generator = validation_datagen.flow_from_directory(validation_dir,target_size=(150,150),batch_size=20,class_mode='binary')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LbO9I4YDCjhk","executionInfo":{"status":"ok","timestamp":1674452031356,"user_tz":-120,"elapsed":416,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}},"outputId":"8a7b66a7-128b-4279-d597-3a4310a91029"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2000 images belonging to 2 classes.\n","Found 1000 images belonging to 2 classes.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"5Th_I_mHFp0H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Fine Tuning our model"],"metadata":{"id":"w4oEp5ctIJWo"}},{"cell_type":"code","source":["from tensorflow.keras import models,layers\n","\n","\n","model = models.Sequential()\n","model.add(conv_base)\n","model.add(layers.Flatten())\n","model.add(layers.Dense(256,activation='relu'))\n","model.add(layers.Dense(1,activation='sigmoid'))\n"],"metadata":{"id":"crZAApA4IRj5","executionInfo":{"status":"ok","timestamp":1674452484477,"user_tz":-120,"elapsed":323,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z_FQK60dIv_T","executionInfo":{"status":"ok","timestamp":1674452503635,"user_tz":-120,"elapsed":15,"user":{"displayName":"Demian Rafeek","userId":"18390949720259940474"}},"outputId":"65dde018-d36b-4a64-a430-4e896319c151"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," vgg16 (Functional)          (None, 4, 4, 512)         14714688  \n","                                                                 \n"," flatten (Flatten)           (None, 8192)              0         \n","                                                                 \n"," dense (Dense)               (None, 256)               2097408   \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 257       \n","                                                                 \n","=================================================================\n","Total params: 16,812,353\n","Trainable params: 16,812,353\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["from tensorflow.keras import optimizers\n","\n","# train the dense layers befor unfreezing the last conv layer in vgg16 model\n","\n","model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=1e-5),metrics=['acc'])\n","history = model.fit_generator(train_generator,steps_per_epoch=100,epochs=5,\n","                              validation_data=validation_generator,validation_steps=50)\n"],"metadata":{"id":"nclqs0bWJYfU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","acc=history.history['acc']\n","val_acc = history.history['val_acc']\n","loss=history.history['loss']\n","loss=history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs,acc,labels='training acc')\n","plt.plot(epochs,val_acc,labels='validation_acc')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(epochs,loss,labels='training loss')\n","plt.plot(epochs,val_loss,labels='validation_loss')\n","plt.legend()\n","plt.show()\n","\n"],"metadata":{"id":"jxBzDWASK8zQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"Y-9rFv8RLlyF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_base.summary()"],"metadata":{"id":"FGgUxwTILYhf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["conv_base.trainable=False\n","\n","for layer in conv_base.layers:\n","  if layer.name == 'block5_conv1':\n","    layers.trainable = True"],"metadata":{"id":"qVP7gz47LYpX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","model.compile(loss='binary_crossentropy',optimizer=optimizers.RMSprop(lr=1e-5),metrics=['acc'])\n","history = model.fit_generator(train_generator,steps_per_epoch=100,epochs=10,\n","                              validation_data=validation_generator,validation_steps=50)"],"metadata":{"id":"ykB9vq1EPVRK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","acc=history.history['acc']\n","val_acc = history.history['val_acc']\n","loss=history.history['loss']\n","loss=history.history['val_loss']\n","\n","epochs = range(len(acc))\n","\n","plt.plot(epochs,acc,labels='training acc')\n","plt.plot(epochs,val_acc,labels='validation_acc')\n","plt.legend()\n","plt.show()\n","\n","plt.plot(epochs,loss,labels='training loss')\n","plt.plot(epochs,val_loss,labels='validation_loss')\n","plt.legend()\n","plt.show()\n","\n"],"metadata":{"id":"ztRnHNasP3OP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XXnm4k-NP3Vp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_generator = test_datagen.flow_from_directory(\n","        test_dir,\n","        target_size=(150, 150),\n","        batch_size=20,\n","        class_mode='binary')\n","\n","test_loss, test_acc = model.evaluate_generator(test_generator, steps=50)\n","print('test acc:', test_acc)"],"metadata":{"id":"2FRH7rtgP3cE"},"execution_count":null,"outputs":[]}]}
